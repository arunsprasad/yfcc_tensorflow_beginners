{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yfcc_05_01_Natural_Language_Processing_with_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxFaX9QPdGknkmageCNLY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunsprasad/yfcc_tensorflow_beginners/blob/master/yfcc_05_01_Natural_Language_Processing_with_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEKyihl-5clZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6fa1232e-4611-48dd-9805-300695bfcbb7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "MAX_LEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZtESMkI8D5O",
        "colab_type": "text"
      },
      "source": [
        "###More Preprocessing\n",
        "If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:\n",
        "- if the review is greater than 250 words then trim off the extra words\n",
        "- if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.\n",
        "\n",
        "Luckily for us keras has a function that can do this for us:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSA67V77bkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAX_LEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAX_LEN)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "622hiLOM8Va-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "4ab48cd8-2599-46f4-a1b8-55e7f31b119d"
      },
      "source": [
        "train_data[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     1,   194,\n",
              "        1153,   194,  8255,    78,   228,     5,     6,  1463,  4369,\n",
              "        5012,   134,    26,     4,   715,     8,   118,  1634,    14,\n",
              "         394,    20,    13,   119,   954,   189,   102,     5,   207,\n",
              "         110,  3103,    21,    14,    69,   188,     8,    30,    23,\n",
              "           7,     4,   249,   126,    93,     4,   114,     9,  2300,\n",
              "        1523,     5,   647,     4,   116,     9,    35,  8163,     4,\n",
              "         229,     9,   340,  1322,     4,   118,     9,     4,   130,\n",
              "        4901,    19,     4,  1002,     5,    89,    29,   952,    46,\n",
              "          37,     4,   455,     9,    45,    43,    38,  1543,  1905,\n",
              "         398,     4,  1649,    26,  6853,     5,   163,    11,  3215,\n",
              "       10156,     4,  1153,     9,   194,   775,     7,  8255, 11596,\n",
              "         349,  2637,   148,   605, 15358,  8003,    15,   123,   125,\n",
              "          68, 23141,  6853,    15,   349,   165,  4362,    98,     5,\n",
              "           4,   228,     9,    43, 36893,  1157,    15,   299,   120,\n",
              "           5,   120,   174,    11,   220,   175,   136,    50,     9,\n",
              "        4373,   228,  8255,     5, 25249,   656,   245,  2350,     5,\n",
              "           4,  9837,   131,   152,   491,    18, 46151,    32,  7464,\n",
              "        1212,    14,     9,     6,   371,    78,    22,   625,    64,\n",
              "        1382,     9,     8,   168,   145,    23,     4,  1690,    15,\n",
              "          16,     4,  1355,     5,    28,     6,    52,   154,   462,\n",
              "          33,    89,    78,   285,    16,   145,    95], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4WM004f9KuE",
        "colab_type": "text"
      },
      "source": [
        "###Creating the Model\n",
        "Now it's time to create the model. We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment. \n",
        "\n",
        "32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaqq-K6S8g1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7axrlxRC-HZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "55b1f318-ca6f-49c9-eba7-ac2de950175f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbHviSoZ-NR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}